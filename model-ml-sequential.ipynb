{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 660\n",
      "Max sequence length: 660\n",
      "Max sequence length: 660\n",
      "Max sequence length: 660\n"
     ]
    }
   ],
   "source": [
    "from models.ml_sequential import prepare_data, run_all\n",
    "import tensorflow as tf\n",
    "# Disable GPU training, comment out to enable\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# Imports used across models\n",
    "from keras.layers import Input, Dense, TimeDistributed, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "features = ['female', 'age', 'height', 'mass', 'ta_set', 'rh_set']\n",
    "features_scaler, output_scaler, X_padded_folds, y_padded_folds, max_len = prepare_data(features)\n",
    "\n",
    "# Define the input/output shape\n",
    "input_shape = (None, X_padded_folds[0].shape[-1])\n",
    "output_shape = y_padded_folds[0].shape[-1]\n",
    "\n",
    "# Train the model with early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Custom log callback\n",
    "class PrintCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f'Epoch: {epoch+1}, loss: {logs[\"loss\"]:.2f}', end='\\r')\n",
    "\n",
    "    def on_train_end(self, epoch):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 32\n",
      "Fold: 1\n",
      "Epoch: 346, loss: 0.03\n",
      "Fold: 2\n",
      "Epoch: 500, loss: 0.06\n",
      "Fold: 3\n",
      "Epoch: 449, loss: 0.04\n",
      "Fold: 4\n",
      "Epoch: 463, loss: 0.03\n",
      "ml_rnn\n",
      "Average TRE RMSE: 0.410779462041641\n",
      "Average MTSK RMSE: 1.2443753602807686\n",
      "Model size: 64\n",
      "Fold: 1\n",
      "Epoch: 383, loss: 0.03\n",
      "Fold: 2\n",
      "Epoch: 336, loss: 0.03\n",
      "Fold: 3\n",
      "Epoch: 474, loss: 0.03\n",
      "Fold: 4\n",
      "Epoch: 335, loss: 0.04\n",
      "ml_rnn\n",
      "Average TRE RMSE: 0.41461371511959283\n",
      "Average MTSK RMSE: 1.2356653420277874\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "# Results from 16 sized model\n",
    "# Average TRE RMSE: 0.40913350652486097\n",
    "# Average MTSK RMSE: 1.2484756718098815\n",
    "\n",
    "# MODEL NAME\n",
    "model_name = 'ml_rnn'\n",
    "model_sizes = [ 32, 64 ]\n",
    "\n",
    "for model_size in model_sizes:\n",
    "\tmodels = []\n",
    "\tprint(\"Model size:\", model_size)\n",
    "\tfor idx, (X_padded, y_padded) in enumerate(zip(X_padded_folds, y_padded_folds)):\n",
    "\t\tfold_number = idx + 1\n",
    "\t\tprint(\"Fold:\", fold_number)\n",
    "\t\t# Model architecture\n",
    "\t\tmodel = Sequential()\n",
    "\t\tmodel.add(Input(shape=input_shape))\n",
    "\t\tmodel.add(SimpleRNN(model_size, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))\n",
    "\t\tmodel.add(TimeDistributed(Dense(8, activation='linear', kernel_regularizer=l2(0.01))))\n",
    "\t\tmodel.add(Dropout(0.2))\n",
    "\t\tmodel.add(TimeDistributed(Dense(output_shape)))\n",
    "\n",
    "\t\t# Compile the model\n",
    "\t\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\t\t# Train the model\n",
    "\t\tearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\t\tmodel.fit(X_padded, y_padded, validation_split=0.2, epochs=500, batch_size=32, callbacks=[PrintCallback(), early_stopping], verbose=0)\n",
    "\n",
    "\t\t# Save the model\n",
    "\t\tmodel.save('model_weights/{}-fold{}-size{}.keras'.format(model_name, fold_number, model_size))\n",
    "\n",
    "\t\tmodels.append(model)\n",
    "\n",
    "\t# Run simulations using trained model\n",
    "\trun_all(models, model_name, features, features_scaler, output_scaler, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 8\n",
      "Fold: 1\n",
      "Epoch: 285, loss: 0.04\n",
      "Fold: 2\n",
      "Epoch: 447, loss: 0.03\n",
      "Fold: 3\n",
      "Epoch: 353, loss: 0.04\n",
      "Fold: 4\n",
      "Epoch: 500, loss: 0.04\n",
      "ml_lstm\n",
      "Average TRE RMSE: 0.4002177547379054\n",
      "Average MTSK RMSE: 1.2118397678835118\n",
      "Model size: 32\n",
      "Fold: 1\n",
      "Epoch: 173, loss: 0.04\n",
      "Fold: 2\n",
      "Epoch: 305, loss: 0.03\n",
      "Fold: 3\n",
      "Epoch: 169, loss: 0.05\n",
      "Fold: 4\n",
      "Epoch: 267, loss: 0.04\n",
      "ml_lstm\n",
      "Average TRE RMSE: 0.40426242564629805\n",
      "Average MTSK RMSE: 1.2130538083625308\n",
      "Model size: 64\n",
      "Fold: 1\n",
      "Epoch: 192, loss: 0.04\n",
      "Fold: 2\n",
      "Epoch: 162, loss: 0.05\n",
      "Fold: 3\n",
      "Epoch: 152, loss: 0.04\n",
      "Fold: 4\n",
      "Epoch: 211, loss: 0.04\n",
      "ml_lstm\n",
      "Average TRE RMSE: 0.40716918527757723\n",
      "Average MTSK RMSE: 1.219020673328306\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "# Results from 16 sized model\n",
    "# Average TRE RMSE: 0.4006921834540827\n",
    "# Average MTSK RMSE: 1.1933293403769494\n",
    "\n",
    "# MODEL NAME\n",
    "model_name = 'ml_lstm'\n",
    "model_sizes = [ 8, 32, 64 ]\n",
    "\n",
    "for model_size in model_sizes:\n",
    "\tmodels = []\n",
    "\tprint(\"Model size:\", model_size)\n",
    "\tfor idx, (X_padded, y_padded) in enumerate(zip(X_padded_folds, y_padded_folds)):\n",
    "\t\tfold_number = idx + 1\n",
    "\t\tprint(\"Fold:\", fold_number)\n",
    "\t\t# Model architecture\n",
    "\t\tmodel = Sequential()\n",
    "\t\tmodel.add(Input(shape=input_shape))\n",
    "\t\tmodel.add(LSTM(model_size, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))\n",
    "\t\tmodel.add(TimeDistributed(Dense(8, activation='linear', kernel_regularizer=l2(0.01))))\n",
    "\t\tmodel.add(Dropout(0.2))\n",
    "\t\tmodel.add(TimeDistributed(Dense(output_shape)))\n",
    "\n",
    "\t\t# Compile the model\n",
    "\t\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\t\t# Train the model\n",
    "\t\tearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\t\tmodel.fit(X_padded, y_padded, validation_split=0.2, epochs=500, batch_size=32, callbacks=[PrintCallback(), early_stopping], verbose=0)\n",
    "\n",
    "\t\t# Save the model\n",
    "\t\tmodel.save('model_weights/{}-fold{}-size{}.keras'.format(model_name, fold_number, model_size))\n",
    "\n",
    "\t\tmodels.append(model)\n",
    "\n",
    "\t# Run simulations using trained model\n",
    "\trun_all(models, model_name, features, features_scaler, output_scaler, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 8\n",
      "Fold: 1\n",
      "Epoch: 369, loss: 0.01\n",
      "Fold: 2\n",
      "Epoch: 500, loss: 0.02\n",
      "Fold: 3\n",
      "Epoch: 391, loss: 0.02\n",
      "Fold: 4\n",
      "Epoch: 500, loss: 0.02\n",
      "ml_gru\n",
      "Average TRE RMSE: 0.3702108755798637\n",
      "Average MTSK RMSE: 1.047010564418845\n",
      "Model size: 32\n",
      "Fold: 1\n",
      "Epoch: 324, loss: 0.01\n",
      "Fold: 2\n",
      "Epoch: 215, loss: 0.02\n",
      "Fold: 3\n",
      "Epoch: 345, loss: 0.01\n",
      "Fold: 4\n",
      "Epoch: 234, loss: 0.01\n",
      "ml_gru\n",
      "Average TRE RMSE: 0.34778583558998105\n",
      "Average MTSK RMSE: 0.9631366050031559\n",
      "Model size: 64\n",
      "Fold: 1\n",
      "Epoch: 226, loss: 0.02\n",
      "Fold: 2\n",
      "Epoch: 206, loss: 0.02\n",
      "Fold: 3\n",
      "Epoch: 273, loss: 0.02\n",
      "Fold: 4\n",
      "Epoch: 209, loss: 0.01\n",
      "ml_gru\n",
      "Average TRE RMSE: 0.33714177906760706\n",
      "Average MTSK RMSE: 0.9706077939508453\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "# Results from 16 sized model\n",
    "# Average TRE RMSE: 0.35102718032762875\n",
    "# Average MTSK RMSE: 0.9882427786586373\n",
    "\n",
    "# MODEL NAME\n",
    "model_name = 'ml_gru'\n",
    "model_sizes = [ 8, 32, 64 ]\n",
    "\n",
    "for model_size in model_sizes:\n",
    "\tmodels = []\n",
    "\tprint(\"Model size:\", model_size)\n",
    "\tfor idx, (X_padded, y_padded) in enumerate(zip(X_padded_folds, y_padded_folds)):\n",
    "\t\tfold_number = idx + 1\n",
    "\t\tprint(\"Fold:\", fold_number)\n",
    "\t\t# Model architecture\n",
    "\t\tmodel = Sequential()\n",
    "\t\tmodel.add(Input(shape=input_shape))\n",
    "\t\tmodel.add(GRU(model_size, return_sequences=True))\n",
    "\t\tmodel.add(TimeDistributed(Dense(8, activation='linear', kernel_regularizer=l2(0.01))))\n",
    "\t\tmodel.add(Dropout(0.2))\n",
    "\t\tmodel.add(TimeDistributed(Dense(output_shape)))\n",
    "\n",
    "\t\t# Compile the model\n",
    "\t\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\t\t# Train the model\n",
    "\t\tearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\t\tmodel.fit(X_padded, y_padded, validation_split=0.2, epochs=500, batch_size=32, callbacks=[PrintCallback(), early_stopping], verbose=0)\n",
    "\n",
    "\t\t# Save the model\n",
    "\t\tmodel.save('model_weights/{}-fold{}-size{}.keras'.format(model_name, fold_number, model_size))\n",
    "\n",
    "\t\tmodels.append(model)\n",
    "\n",
    "\t# Run simulations using trained model\n",
    "\trun_all(models, model_name, features, features_scaler, output_scaler, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select best performing model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_rnn\n",
      "Average TRE RMSE: 0.40913350652486097\n",
      "Average MTSK RMSE: 1.2484756718098815\n",
      "ml_lstm\n",
      "Average TRE RMSE: 0.4006921834540827\n",
      "Average MTSK RMSE: 1.1933293403769494\n",
      "ml_gru\n",
      "Average TRE RMSE: 0.34778583558998105\n",
      "Average MTSK RMSE: 0.9631366050031559\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model_name = 'ml_gru'\n",
    "model_size = 32\n",
    "\n",
    "def get_results_for_model_size(model_name, model_size=None):\n",
    "\tmodels = []\n",
    "\tfor i in range(4):\n",
    "\t\tfold_number = i + 1\n",
    "\t\tif model_size:\n",
    "\t\t\tmodel = keras.models.load_model(f'model_weights/{model_name}-fold{fold_number}-size{model_size}.keras')\n",
    "\t\telse:\n",
    "\t\t\tmodel = keras.models.load_model(f'model_weights/{model_name}-fold{fold_number}.keras')\n",
    "\t\tmodels.append(model)\n",
    "\t# Run simulations using trained models from each fold\n",
    "\trun_all(models, model_name, features, features_scaler, output_scaler, max_len)\n",
    "\n",
    "get_results_for_model_size('ml_rnn') # Default to previously trained 16 unit model\n",
    "get_results_for_model_size('ml_lstm') # Default to previously trained 16 unit model\n",
    "get_results_for_model_size('ml_gru', 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, loss: 0.03\n",
      "ml_tcn\n",
      "Average TRE RMSE: 0.4642991150064746\n",
      "Average MTSK RMSE: 1.6289565766153424\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Conv1D\n",
    "\n",
    "# # MODEL NAME\n",
    "# model_name = 'ml_tcn'\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Input(shape=input_shape))\n",
    "# model.add(Conv1D(16, kernel_size=4, activation='linear', padding='causal', kernel_regularizer=l2(0.01)))\n",
    "# model.add(TimeDistributed(Dense(8, activation='linear', kernel_regularizer=l2(0.01))))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(TimeDistributed(Dense(output_shape)))\n",
    "\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model.fit(X_padded, y_padded, validation_split=0.2, epochs=500, batch_size=32, callbacks=[PrintCallback(), early_stopping], verbose=0)\n",
    "\n",
    "# model.save('model_weights/{}.keras'.format(model_name))\n",
    "\n",
    "# # Run simulations using trained model\n",
    "# run_all(model, model_name, features, features_scaler, output_scaler, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, loss: 0.03\n",
      "ml_seq2seq\n",
      "Average TRE RMSE: 0.4447912235248274\n",
      "Average MTSK RMSE: 1.4460834447802842\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import LSTM, Attention, Concatenate\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # MODEL NAME\n",
    "# model_name = 'ml_seq2seq'\n",
    "\n",
    "# encoder_inputs = Input(shape=input_shape)\n",
    "# encoder_lstm = LSTM(16, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01))\n",
    "# encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# decoder_inputs = Input(shape=input_shape)\n",
    "# decoder_lstm = LSTM(16, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01))\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "\n",
    "# attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "# decoder_concat = Concatenate()([decoder_outputs, attention])\n",
    "# decoder_dense = TimeDistributed(Dense(output_shape))\n",
    "# decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model.fit([X_padded, X_padded], y_padded, validation_split=0.2, epochs=500, batch_size=32, callbacks=[PrintCallback(), early_stopping], verbose=0)\n",
    "\n",
    "# model.save('model_weights/{}.keras'.format(model_name))\n",
    "\n",
    "# # Run simulations using trained model\n",
    "# run_all(model, model_name, features, features_scaler, output_scaler, max_len, is_transformer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
