{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female       0\n",
       "age          0\n",
       "height       0\n",
       "mass         0\n",
       "ta_set       0\n",
       "rh_set       0\n",
       "tre_int      0\n",
       "mtsk_int     0\n",
       "id_all       0\n",
       "unique_id    0\n",
       "study        0\n",
       "condition    0\n",
       "time         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import dataset\n",
    "df = pd.read_csv('./dataset/230322_OlderPredictTc_data_thermal.csv')\n",
    "\n",
    "# Only use previous values from same individual\n",
    "# df['previous_tre_int'] = df.groupby('id_all')['tre_int'].shift(1)\n",
    "# df['previous_mtsk_int'] = df.groupby('id_all')['mtsk_int'].shift(1)\n",
    "\n",
    "# Select only time > 0\n",
    "df = df[df.time > 0]\n",
    "\n",
    "# Unique ID to identify an individual\n",
    "df['unique_id'] = df['study'].astype(str) + '_' + df['condition'].astype(str) + '_' + df['id_all'].astype(str)\n",
    "\n",
    "# Select only features and output\n",
    "features = ['female', 'age', 'height', 'mass', 'ta_set', 'rh_set']\n",
    "output = ['tre_int', 'mtsk_int']\n",
    "df = df[features + output + ['id_all', 'unique_id', 'study', 'condition', 'time']]\n",
    "\n",
    "# Create train_df based on participants assigned to training set\n",
    "train_ids = [46, 34, 68, 30, 40, 98, 89, 65, 24, 58, 85, 67, 28, 39, 35, 77, 26,\n",
    "             80, 70, 37, 52, 56, 74, 78, 71, 60, 86, 43, 91, 82, 22, 59, 21, 87,\n",
    "             95, 66, 44, 25, 76, 94, 53, 32, 73, 23, 49]\n",
    "train_df = df[df['id_all'].isin(train_ids)]\n",
    "\n",
    "# Check data\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s5068337/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.4806 - val_loss: 0.2586\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - loss: 0.2190 - val_loss: 0.0747\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - loss: 0.0695 - val_loss: 0.0230\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - loss: 0.0422 - val_loss: 0.0491\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - loss: 0.0611 - val_loss: 0.0378\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - loss: 0.0473 - val_loss: 0.0199\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - loss: 0.0259 - val_loss: 0.0193\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - loss: 0.0192 - val_loss: 0.0270\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - loss: 0.0209 - val_loss: 0.0327\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - loss: 0.0192 - val_loss: 0.0323\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - loss: 0.0174 - val_loss: 0.0278\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - loss: 0.0140 - val_loss: 0.0225\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - loss: 0.0122 - val_loss: 0.0192\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - loss: 0.0135 - val_loss: 0.0181\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - loss: 0.0139 - val_loss: 0.0190\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - loss: 0.0126 - val_loss: 0.0213\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - loss: 0.0120 - val_loss: 0.0238\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 0.0118 - val_loss: 0.0247\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 0.0122 - val_loss: 0.0232\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - loss: 0.0116 - val_loss: 0.0207\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - loss: 0.0115 - val_loss: 0.0186\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - loss: 0.0111 - val_loss: 0.0172\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - loss: 0.0114 - val_loss: 0.0167\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - loss: 0.0111 - val_loss: 0.0169\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - loss: 0.0111 - val_loss: 0.0180\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - loss: 0.0107 - val_loss: 0.0186\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - loss: 0.0113 - val_loss: 0.0180\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - loss: 0.0110 - val_loss: 0.0172\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - loss: 0.0107 - val_loss: 0.0157\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - loss: 0.0107 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - loss: 0.0106 - val_loss: 0.0151\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - loss: 0.0106 - val_loss: 0.0152\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - loss: 0.0107 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - loss: 0.0107 - val_loss: 0.0146\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - loss: 0.0103 - val_loss: 0.0147\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - loss: 0.0102 - val_loss: 0.0146\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 228ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - loss: 0.0099 - val_loss: 0.0139\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - loss: 0.0101 - val_loss: 0.0143\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - loss: 0.0101 - val_loss: 0.0139\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249ms/step - loss: 0.0097 - val_loss: 0.0138\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step - loss: 0.0095 - val_loss: 0.0134\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step - loss: 0.0096 - val_loss: 0.0136\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - loss: 0.0092 - val_loss: 0.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3facaebb0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "# Reset index\n",
    "train_df.reset_index(inplace=True)\n",
    "\n",
    "# Scalars\n",
    "features_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "output_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# Fit scalers\n",
    "X_scaled = features_scaler.fit_transform(train_df[features])\n",
    "y_scaled = output_scaler.fit_transform(train_df[output])\n",
    "\n",
    "# For each feature row, we need to map it so that\n",
    "# Create sequences based on unique_id\n",
    "unique_ids = train_df['unique_id'].unique()\n",
    "X_seq, y_seq = [], []\n",
    "for uid in unique_ids:\n",
    "    seq_data = train_df[train_df['unique_id'] == uid]\n",
    "    X_seq.append(X_scaled[seq_data.index])\n",
    "    y_seq.append(y_scaled[seq_data.index])\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "max_len = max(len(seq) for seq in X_seq)\n",
    "X_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0, 0)), mode='constant') for seq in X_seq])\n",
    "y_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0, 0)), mode='constant') for seq in y_seq])\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(None, X_padded.shape[-1]), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(y_padded.shape[-1])))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_padded, y_padded, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATE\n",
    "from helpers import get_sample\n",
    "\n",
    "def run_and_save_trial(study, condition):\n",
    "    # Get sample\n",
    "    sample = get_sample(study, condition)\n",
    "\n",
    "    # Unique ID to identify an individual\n",
    "    sample['unique_id'] = sample['study'].astype(str) + '_' + sample['condition'].astype(str) + '_' + sample['id_all'].astype(str)\n",
    "\n",
    "    # Fit scalers\n",
    "    all_X_scaled = features_scaler.fit_transform(sample[features])\n",
    "\n",
    "    # Create sequences based on unique_id\n",
    "    all_unique_ids = sample['unique_id'].unique()\n",
    "    all_X_seq = []\n",
    "    seq_lengths = []  # Store the original sequence lengths\n",
    "\n",
    "    for uid in all_unique_ids:\n",
    "        seq_data = sample['unique_id'] == uid\n",
    "        data_for_uid = all_X_scaled[seq_data]\n",
    "        all_X_seq.append(data_for_uid)\n",
    "        seq_lengths.append(len(data_for_uid))  # Store the original sequence length\n",
    "\n",
    "    # Pad sequences to have the same length\n",
    "    all_X_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0, 0)), mode='constant') for seq in all_X_seq])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(all_X_padded)\n",
    "\n",
    "    # Remove predictions corresponding to padded inputs\n",
    "    unpadded_predictions = []\n",
    "    for i, length in enumerate(seq_lengths):\n",
    "        unpadded_predictions.append(predictions[i, :length])\n",
    "\n",
    "    # Flatten the unpadded predictions\n",
    "    unpadded_predictions = np.concatenate(unpadded_predictions, axis=0)\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    unpadded_predictions = output_scaler.inverse_transform(unpadded_predictions)\n",
    "\n",
    "    all_core_temps = unpadded_predictions[:, 0]\n",
    "    all_skin_temps = unpadded_predictions[:, 1]\n",
    "\n",
    "    print(all_core_temps.shape[0])\n",
    "    print(all_skin_temps.shape[0])\n",
    "    print(sample.shape[0])\n",
    "\n",
    "    # Save to csv\n",
    "    df = pd.DataFrame(all_core_temps, columns=[\"tre_predicted\"])\n",
    "    df[\"mtsk_predicted\"] = all_skin_temps\n",
    "    df.to_csv('results/regression-{}-{}.csv'.format(study, condition), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "31860\n",
      "31860\n",
      "31860\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "7680\n",
      "7680\n",
      "7680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "7680\n",
      "7680\n",
      "7680\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "17760\n",
      "17760\n",
      "17760\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "16800\n",
      "16800\n",
      "16800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "10260\n",
      "10260\n",
      "10260\n"
     ]
    }
   ],
   "source": [
    "run_and_save_trial('heatwave 1 (prolonged)', 'hot')\n",
    "run_and_save_trial('heatwave 2 (indoor)', 'cool')\n",
    "run_and_save_trial('heatwave 2 (indoor)', 'temp')\n",
    "run_and_save_trial('heatwave 2 (indoor)', 'warm')\n",
    "run_and_save_trial('heatwave 2 (indoor)', 'hot')\n",
    "run_and_save_trial('heatwave 3 (cooling)', 'hot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
